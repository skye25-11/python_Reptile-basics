r=requests.get(url)
get(url) 构造一个向服务器请求资源的Request（请求）对象 库生成的
r 返回一个包含服务器资源的Response（响应）对象

requests.get(url,params=None,**kwargs)
url:拟获取页面的url链接
params：url中的额外参数，字典或字节流格式，可选
**kwargs：12个控制访问的参数

Response对象的属性
r.status_code       HTTP请求的返回状态，200表示连接成功，404表示失败
r.text              HTTP响应内容的字符串形式，即，url对应的页面内容
r.encoding          从HTTP header中猜测的响应内容编码方式
r.apparent_encoding 从内容中分析出的响应内容编码方式（备选编码方式）
r.content           HTTP响应内容的二进制形式

步骤：》r.status_code 》200 r.text  /r.encoding  /r.apparent_encoding  /r.content
if 》r.status_code 》404或其他 》某些原因出错 将产生异常

r.encoding：如果header中不存在charset，则认为编码为ISO‐8859‐1
            r.text根据r.encoding显示网页内容
r.apparent_encoding：根据网页内容分析出的编码方式 可以看作是r.encoding的备选

Requests库的异常
request.ConnectionError  网络连接错误异常，如DNS查询失败、拒绝连接等
requests.HTTPError       HTTP错误异常
requests.URLRequired     URL缺失异常
requests.TooManyRedirects   超过最大重定向次数，产生重定向异常
requests.ConnectTimeout   连接远程服务器超时异常
requests.Timeout         请求URL超时，产生超时异常

Response的异常
r.raise_for_status()     如果不是200，产生异常requests.HTTPError

HTTP协议
HTTP，Hypertext Transfer Protocol，超文本传输协议
HTTP是一个基于“请求与响应”模式的、无状态的应用层协议
HTTP协议采用URL作为定位网络资源的标识，

URL格式如下：
http://host[:port][path]
host: 合法的Internet主机域名或IP地址
port: 端口号，缺省端口为80
path: 请求资源的路径

HTTP URL的理解：
URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源

requests.request()构造一个请求，支撑以下各方法的基础方法
requests.get()  获取HTML网页的主要方法，对应于HTTP的GET(请求获取URL位置的资源)
requests.head() 获取HTML网页头信息的方法，对应于HTTP的HEAD(请求获取URL位置资源的响应消息报告，即获得该资源的头部信息)
requests.post()  向HTML网页提交POST请求的方法，对应于HTTP的POST(请求向URL位置的资源后附加新的数据)
requests.put()   向HTML网页提交PUT请求的方法，对应于HTTP的PUT(请求向URL位置存储一个资源，覆盖原URL位置的资源)
requests.patch() 向HTML网页提交局部修改请求，对应于HTTP的PATCH(请求局部更新URL位置的资源，即改变该处资源的部分内容)
requests.delete() 向HTML页面提交删除请求，对应于HTTP的DELETE(请求删除URL位置存储的资源)

PATCH和PUT的区别：
假设URL位置有一组数据UserInfo，包括UserID、UserName等20个字段
需求：用户修改了UserName，其他不变
•采用PATCH，仅向URL提交UserName的局部更新请求
•采用PUT，必须将所有20个字段一并提交到URL，未提交字段被删除
PATCH的最主要好处：节省网络带宽

方法解析
requests.request(method,url,**kwargs)
∙method : 请求方式
r = requests.request('GET',url,**kwargs)
r = requests.request('HEAD',url,**kwargs)
r = requests.request('POST',url,**kwargs)
r = requests.request('PUT',url,**kwargs)
r = requests.request('PATCH',url,**kwargs)
r = requests.request('delete',url,**kwargs)
r = requests.request('OPTIONS',url,**kwargs)

**kwargs: 控制访问的参数，均为可选项
{
params: 字典或字节序列，作为参数增加到url中
data    : 字典、字节序列或文件对象，作为Request的内容
json: JSON格式的数据，作为Request的内容
headers : 字典，HTTP定制头
cookies : 字典或CookieJar，Request中的cookie
auth: 元组，支持HTTP认证功能
files   : 字典类型，传输文件
timeout : 设定超时时间，秒为单位
proxies : 字典类型，设定访问代理服务器，可以增加登录认证 （可以隐藏用户原的ip地址）
高级：
allow_redirects: True/False，默认为True，重定向开关
stream  : True/False，默认为True，获取内容立即下载开关
verify  : True/False，默认为True，认证SSL证书开关
cert    : 本地SSL证书路径
}

requests.get(url,params=None, **kwargs)
∙ url: 拟获取页面的url链接
∙ params: url中的额外参数，字典或字节流格式，可选
∙**kwargs: 12个控制访问的参数

requests.head(url,**kwargs)
∙ url: 拟获取页面的url链接
∙**kwargs: 13个控制访问的参数

requests.post(url,data=None, json=None, **kwargs)
∙ url: 拟更新页面的url链接
∙ data : 字典、字节序列或文件，Request的内容
∙ json: JSON格式的数据，Request的内容
∙**kwargs: 12个控制访问的参数

requests.put(url,data=None, **kwargs)
∙ url: 拟更新页面的url链接
∙ data : 字典、字节序列或文件，Request的内容
∙ **kwargs: 12个控制访问的参数

requests.patch(url,data=None, **kwargs)
∙ url: 拟更新页面的url链接
∙ data : 字典、字节序列或文件，Request的内容
∙ **kwargs: 12个控制访问的参数

requests.delete(url,**kwargs)
∙ url: 拟删除页面的url链接
∙**kwargs: 12个控制访问的参数

盗亦有道
Robots协议
Robots Exclusion Standard，网络爬虫排除标准
作用：
网站告知网络爬虫哪些页面可以抓取，哪些不行
形式：
在网站根目录下的robots.txt文件

京东的Robots协议
https://www.jd.com/robots.txt
User‐agent: * 
Disallow: /?* 
Disallow: /pop/*.html 
Disallow: /pinpai/*.html?* 
恶意爬虫禁止
User‐agent: EtaoSpider
Disallow: / 
User‐agent: HuihuiSpider
Disallow: / 
User‐agent: GwdangSpider
Disallow: / 
User‐agent: WochachaSpider
Disallow: /

# 注释，*代表所有，/代表根目录
User‐agent: * 
Disallow: / 